outlier(train, typea)
outlier(train, obesity)
outlier(train, alcohol)
outlier(train, age)
boxplot(train)
any(is.na(data))
any(is.na(train))
library(leaps)
data= read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data", sep=",",head=T,row.names=1)
sub <- sample(nrow(data), floor(nrow(data) * 0.5))
train<-data[sub,]
valid<-data[-sub,]
summary(train)
pairs(train)
cor(data[,c(1,2,3,4,6,7,8,9,10)])
boxplot(chd ~ famhist, data = train)
any(is.na(train))
boxplot(train)
outlier <- function(dt, var) {
var_name <- eval(substitute(var),eval(dt))
na1 <- sum(is.na(var_name))
m1 <- mean(var_name, na.rm = T)
par(mfrow=c(2, 2), oma=c(0,0,3,0))
boxplot(var_name, main="With outliers")
hist(var_name, main="With outliers", xlab=NA, ylab=NA)
outlier <- boxplot.stats(var_name)$out
mo <- mean(outlier)
var_name <- ifelse(var_name %in% outlier, NA, var_name)
boxplot(var_name, main="Without outliers")
hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
title("Outlier Check", outer=TRUE)
na2 <- sum(is.na(var_name))
cat("Outliers identified:", na2 - na1, "\n")
cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "\n")
cat("Mean of the outliers:", round(mo, 2), "\n")
m2 <- mean(var_name, na.rm = T)
cat("Mean without removing outliers:", round(m1, 2), "\n")
cat("Mean if we remove outliers:", round(m2, 2), "\n")
dt[as.character(substitute(var))] <- invisible(var_name)
assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
cat("Outliers successfully removed", "\n")
return(invisible(dt))
}
outlier(train, sbp)
outlier(train, tobacco)
outlier(train, ldl)
outlier(train, adiposity)
outlier(train, typea)
outlier(train, obesity)
outlier(train, alcohol)
outlier(train, age)
boxplot(train)
var_name <- ifelse(var_name %in% outlier, NA, var_name)
any(is.na(train))
train =na.omit(Hitters )
train =na.omit(train )
any(is.na(train))
boxplot(train)
boxplot(train)
regfit.full <- regsubsets(chd~., data = train)
reg.summary <- summary(regfit.full)
reg.summary
plot(reg.summary$bic, xlab = "Number of variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
sa.heart.fit <- glm(chd ~ age + ldl, family = binomial, data=train)
coef(sa.heart.fit)
pairs(train)
cor(data[,c(1,2,3,4,6,7,8,9,10)])
cor(data[,c(1,2,3,4,6,7,8,9,10)])
summary(train)
cor(data[,c(1,2,3,4,5,6,7,8,9,10)])
sa.heart.fit = glm(chd ~ age + ldl, family = binomial, data=train)
coef(sa.heart.fit)
lda.fit = lda(chd ~ age + ldl, data=train)
install.packages("MASS")
library(MASS)
lda.fit = lda(chd ~ age + ldl, data=train)
lda.fit
lda.pred=predict (lda.fit , train)
names(lda .pred)
names(lda.pred)
lda.class =lda.pred$class
table(lda.class ,Direction)
table(lda.class)
mean(lda.class)
sum(lda.pred$posterior[,1] >=.5)
sum(lda.pred$posterior[,1] <.5)
lda.fit = lda(chd ~ age + ldl, data=train,cv=TRUE)
lda.fit
lda.fit = lda(chd ~ age + ldl, data=train,cv=TRUE)
lda.fit
lda.pred=predict(lda.fit , train)
table(true=train, predict=predict.lda$class)
table(true=train, predict=lda.pred$class)
table(true=train[,2], predict=lda.pred$class)
table(true=train[,3], predict=lda.pred$class)
table(true=train[,9], predict=lda.pred$class)
table(true=train[,10], predict=lda.pred$class)
lda.pred=predict(lda.fit , train)
lda.class =lda.pred$class
table(lda.class)
library(gmodels)
package.install("gmodels")
install.packages("gmodels")
library(gmodels)
CrossTable(predict.lda$class,train[,9])
CrossTable(lda.pred$class,train[,9])
CrossTable(lda.pred$class,train)
library(ROCR)
install.packages("ROCR")
library(ROCR)
library(gplots)
library(ROCR)
scores <- predict(lda.fit, newdata= train)$posterior
pred <- prediction( scores, labels= train$test )
pred <- prediction( scores, labels= train$chd )
perf <- performance(pred, "tpr", "fpr")
pred <- prediction( scores, labels= train$chd )
pred <- prediction( scores, labels= train)
pred <- prediction( scores, labels= train$chd,age)
pred <- prediction( scores, labels= train$chd + age)
pred <- prediction( scores, labels= train$age + ldl)
pred <- prediction( scores, labels= train$age, ldl)
scores <- predict(lda.fit, newdata= train)$posterior[,2]
pred <- prediction( scores, labels= train$chd)
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, main="LDA")
unlist(attributes(performance(pred, "auc"))$y.values)
library(bestglm)
install.packages("bestglm")
library(bestglm)
train.for.bestglm <- train
dimnames(train.for.bestglm)[[2]][9] <- "y"
fit.bestglm <- bestglm(Xy = train.for.bestglm,
family = binomial, IC = "AIC", method = "exhaustive")
View(train)
View(train)
View(data)
View(data)
dimnames(train.for.bestglm)[[2]][11] <- "y"
dimnames(train.for.bestglm)[[2]][11] <- "y"
train.for.bestglm <- train
dimnames(train.for.bestglm)[[2]][10] <- "y"
fit.bestglm <- bestglm(Xy = train.for.bestglm,
family = binomial, IC = "AIC", method = "exhaustive")
summary(fit.bestglm)
fit.bestglm$BestModels
fit.bestglm <- bestglm(Xy = train.for.bestglm,
family = binomial, IC = "BIC", method = "exhaustive")
summary(fit.bestglm)
fit.bestglm$BestModels
sa.heart.fit = glm(chd ~ age + ldl, family = binomial, data=train)
coef(sa.heart.fit)
newtrain <- sample(x=1:nrow(train), size=nrow(train)/4)
fit.train <- glm(test ~., family=binomial, data=train[newtrain,])
fit.train <- glm(chd ~age + ldl, family=binomial, data=train[newtrain,])
summary(fit.train)
summary(fit)
newtrain <- sample(x=1:nrow(train), size=nrow(train)/4)
fit.train <- glm(chd ~age + ldl, family=binomial, data=train[newtrain,])
summary(fit.train)
summary(fit)
summary(sa.heart.fit)
summary(fit.train)
scores <- predict(fit.train, newdata=train[newtrain,], type="response")
pred <- prediction(scores, labels=train[newtrain,]$chd )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=F, main="In-sample ROC curve")
plot(perf, colorize=F, main="In-sample ROC curve")
unlist(attributes(performance(pred, "auc"))$y.values)
fit.train <- glm(chd ~age + ldl, family=binomial, data=train)
summary(fit.train)
summary(fit)
summary(sa.heart.fit)
scores <- predict(sa.heart.fit, newdata=train, type="response")
pred <- prediction(scores, labels=train$chd )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=F, main="In-sample ROC curve")
unlist(attributes(performance(pred, "auc"))$y.values)
scores <- predict(sa.heart.fit, newdata=valid, type="response")
pred <- prediction( scores, labels=pima[-train,]$test )
perf <- performance(pred, "tpr", "fpr")
pred <- prediction( scores, labels=valid$chd )
perf <- performance(pred, "tpr", "fpr")
scores <- predict(sa.heart.fit, newdata=valid, type="response")
pred <- prediction( scores, labels=valid$chd )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, add=TRUE)
unlist(attributes(performance(pred, "auc"))$y.values)
scores <- predict(lda.fit, newdata= train)$posterior[,2]
pred <- prediction( scores, labels= train$chd)
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, main="LDA")
unlist(attributes(performance(pred, "auc"))$y.values)
predict.lda <- predict(fit.lda, pimaValid[,-9])
unlist(attributes(performance(pred, "auc"))$y.values)
fit.lda <- lda(x=as.matrix(train[,-10]), grouping= train[,10], cv=TRUE)
any(is.na(train))
fit.lda <- lda(x=as.matrix(train[,-10]), grouping= train[,10], cv=TRUE)
fit.lda <- lda(x=as.matrix(train[,-10]), grouping= train[,11], cv=TRUE)
fit.lda <- lda(x=as.matrix(train[,-10]), grouping= train[,9], cv=TRUE)
lda.fit = lda(chd ~ age + ldl, data=train,cv=TRUE)
scores <- predict(lda.fit, newdata= train[,-10])$posterior[,2]
scores <- predict(lda.fit, newdata= train)$posterior[,2]
pred <- prediction( scores, labels= train$chd )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, main="LDA")
unlist(attributes(performance(pred, "auc"))$y.values)
scores <- predict(lda.fit, newdata= train)$posterior[,2]
pred <- prediction( scores, labels= train$chd )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, main="LDA")
unlist(attributes(performance(pred, "auc"))$y.values)
scores <- predict(lda.fit, newdata= train)$posterior
pred <- prediction( scores, labels= train$chd )
scores <- predict(lda.fit, newdata= train)$posterior[,3]
predict.lda <- predict(lda.fit, valid)
table(true= pimaValid[,9], predict=predict.lda$class)
table(true= valid, predict=predict.lda$class)
lda.pred=predict(lda.fit , valid)
lda.class =lda.pred$class
table(lda.class)
scores <- predict(lda.fit, newdata= valid)$posterior[,2]
pred <- prediction( scores, labels= valid$chd )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, main="LDA", add=TRUE)
unlist(attributes(performance(pred, "auc"))$y.values)
pred <- prediction( scores, labels= valid$age )
pred <- prediction( scores, labels= valid$famhist )
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize=T, main="LDA", add=TRUE)
unlist(attributes(performance(pred, "auc"))$y.values)
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
# Read data
data= read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data", sep=",",head=T,row.names=1)
# Read data
data= read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data", sep=",",head=T,row.names=1)
install.packages("rmarkdown")
unlink('D:/Dropbox/CS6140/hw3/1_cache', recursive = TRUE)
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("leaps")
install.packages("MASS")
install.packages("glmnet")
install.packages("ROCR")
install.packages("pamr")
knitr::opts_chunk$set(echo = TRUE)
#Let's compare thresholds=1 and 2 to illustrate the effect of shrinkage
pamr.confusion(fit.cv.pamr, threshold=0.137)
library(pamr)
# Reformat the dataset for parm
pamrTrain <- list(x=t(as.matrix(train[,-10])), y=train[,10])
pamrValid <- list(x=t(as.matrix(valid[,-10])), y=valid[,10])
# Fit the classifier on the entire training set
fit.pamr <- pamr.train(pamrTrain)
fit.pamr
# Use cross-validation to select the best regularization parameter
fit.cv.pamr <- pamr.cv(fit.pamr, pamrTrain)
fit.cv.pamr
# Manually select the threshold depending on the plots and on the confusion matrix
pamr.plotcv(fit.cv.pamr)
knitr::opts_chunk$set(echo = TRUE)
# Read data
data= read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data", sep=",",head=T,row.names=1)
set.seed(1)
sub <- sample(nrow(data), floor(nrow(data)/2))
train<-data[sub,]
valid<-data[-sub,]
head(train)
# numeric categorical column
train$famhist = as.numeric(train$famhist)
valid$famhist = as.numeric(train$famhist)
## One-variable summary
summary(train)
# Two-variable summary
pairs(train)
# Correlation coefficients ###
round(cor(train),3)
# Missing values ###
any(is.na(train))
# Outliers
boxplot(train)
library(leaps)
#performs all subset selection (best subset selection)
regfit.full <- regsubsets(chd~., data = train)
reg.summary <- summary(regfit.full)
reg.summary
#Perform variable selection using all subsets selection BIC criteria.
plot(reg.summary$bic, xlab = "Number of variables", ylab = "BIC", type = "l")
#Getting number of parameters
which.min(reg.summary$bic)
# Based on the random train data set, the
# Apply logistic regression
sa.heart.fit = glm(chd ~ age + ldl + famhist, family = binomial, data=train)
summary(sa.heart.fit)
coef(sa.heart.fit)
# The logistic model is:
# log(chd/(1-chd)) = -5.38137237 + 0.05354403 x age + 0.25546871 x ldl + 0.79596898 x famhist + error
# age and ldl have correlation of 0.3
library(MASS)
lda.fit = lda(chd ~ ., data=train)
lda.fit
plot(lda.fit)
library(glmnet)
x <- model.matrix(chd~.,train)[,-1]
y <- train$chd
grid = 10^seq(10,-2, length = 100)
lasso.mod <- glmnet(x,y, alpha = 1, lambda = grid)
plot(lasso.mod, main = "Lasso regression", label = TRUE, xvar = "lambda", xlim = c(-5,5))
cv.out <- cv.glmnet(x,y,alpha = 1)
plot(cv.out)
# find lambda
bestlam.lasso <- cv.out$lambda.min
bestlam.lasso
#best log(lambda)
log(bestlam.lasso)
lasso.mode <- glmnet(x, y, alpha=1, lambda = bestlam.lasso)
predict(lasso.mode, s = bestlam.lasso, type = "coefficients")[1:10,]
lasso.fit = glm(chd ~ tobacco + ldl + famhist + typea + obesity + age, family = binomial, data=train)
summary(lasso.fit)
coef(lasso.fit)
library(pamr)
# Reformat the dataset for parm
pamrTrain <- list(x=t(as.matrix(train[,-10])), y=train[,10])
pamrValid <- list(x=t(as.matrix(valid[,-10])), y=valid[,10])
# Fit the classifier on the entire training set
fit.pamr <- pamr.train(pamrTrain)
fit.pamr
# Use cross-validation to select the best regularization parameter
fit.cv.pamr <- pamr.cv(fit.pamr, pamrTrain)
fit.cv.pamr
# Manually select the threshold depending on the plots and on the confusion matrix
pamr.plotcv(fit.cv.pamr)
#Let's compare thresholds=1 and 2 to illustrate the effect of shrinkage
pamr.confusion(fit.cv.pamr, threshold=0.137)
pamr.confusion(fit.cv.pamr, threshold=0.273)
#Get the best threshhold
thresh <- max(fit.cv.pamr$threshold[fit.cv.pamr$error==min(fit.cv.pamr$error)])
thresh
# Refit the classifier on the full dataset, but using the threshold
fit.pamr <- pamr.train(pamrTrain, threshold=0.1367487)
fit_pamr(pamrTrain$x, pamrTrain$y, threshold = 0.1367487, thres_fun = function(thr, err) median(thr[err == min(err)]), slim = FALSE)
fit_pamr(pamrTrain$x, pamrTrain$y, threshold = 0.1367487, thres_fun = function(thr, err) median(thr[err == min(err)]), slim = FALSE)
#Let's compare thresholds=1 and 2 to illustrate the effect of shrinkage
pamr.confusion(fit.cv.pamr, threshold=0.137)
pamr.confusion(fit.cv.pamr, threshold=0.273)
#Get the best threshhold
thresh <- max(fit.cv.pamr$threshold[fit.cv.pamr$error==min(fit.cv.pamr$error)])
thresh
# Refit the classifier on the full dataset, but using the threshold
fit.pamr <- pamr.train(pamrTrain, threshold=0.1367487)
fit_pamr
pamr.plotcen(pamrTrain, fit.pamr, threshold=0.1367487)
pamr.plotcen(pamrTrain$x, fit.pamr, threshold=0.1367487)
pamr.plotcen(pamrTrain, fit.pamr, threshold=0.1367487)
set.seed(120)
mydata <- list(x=x,y=y)
mytrain <-   pamr.train(mydata)
mycv <- pamr.cv(mytrain,mydata)
set.seed(120)
mydata <- list(x=x,y=y)
mytrain <-   pamr.train(mydata)
pamr.plotcen(mytrain, mydata, threshold=2)
mydata <- list(x=x,y=y)
mytrain <-   pamr.train(mydata)
pamr.plotcen(mytrain, mydata, threshold=2)
knitr::opts_chunk$set(echo = TRUE)
# Read data
data= read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data", sep=",",head=T,row.names=1)
set.seed(1)
sub <- sample(nrow(data), floor(nrow(data)/2))
train<-data[sub,]
valid<-data[-sub,]
head(train)
# numeric categorical column
train$famhist = as.numeric(train$famhist)
valid$famhist = as.numeric(train$famhist)
## One-variable summary
summary(train)
# Two-variable summary
pairs(train)
# Correlation coefficients ###
round(cor(train),3)
# Missing values ###
any(is.na(train))
# Outliers
boxplot(train)
library(leaps)
#performs all subset selection (best subset selection)
regfit.full <- regsubsets(chd~., data = train)
reg.summary <- summary(regfit.full)
reg.summary
#Perform variable selection using all subsets selection BIC criteria.
plot(reg.summary$bic, xlab = "Number of variables", ylab = "BIC", type = "l")
#Getting number of parameters
which.min(reg.summary$bic)
# Based on the random train data set, the
# Apply logistic regression
sa.heart.fit = glm(chd ~ age + ldl + famhist, family = binomial, data=train)
summary(sa.heart.fit)
coef(sa.heart.fit)
# The logistic model is:
# log(chd/(1-chd)) = -5.38137237 + 0.05354403 x age + 0.25546871 x ldl + 0.79596898 x famhist + error
# age and ldl have correlation of 0.3
library(MASS)
lda.fit = lda(chd ~ ., data=train)
lda.fit
plot(lda.fit)
library(glmnet)
x <- model.matrix(chd~.,train)[,-1]
y <- train$chd
grid = 10^seq(10,-2, length = 100)
lasso.mod <- glmnet(x,y, alpha = 1, lambda = grid)
plot(lasso.mod, main = "Lasso regression", label = TRUE, xvar = "lambda", xlim = c(-5,5))
cv.out <- cv.glmnet(x,y,alpha = 1)
plot(cv.out)
# find lambda
bestlam.lasso <- cv.out$lambda.min
bestlam.lasso
#best log(lambda)
log(bestlam.lasso)
lasso.mode <- glmnet(x, y, alpha=1, lambda = bestlam.lasso)
predict(lasso.mode, s = bestlam.lasso, type = "coefficients")[1:10,]
lasso.fit = glm(chd ~ tobacco + ldl + famhist + typea + obesity + age, family = binomial, data=train)
summary(lasso.fit)
coef(lasso.fit)
library(pamr)
# Reformat the dataset for parm
pamrTrain <- list(x=t(as.matrix(train[,-10])), y=train[,10])
pamrValid <- list(x=t(as.matrix(valid[,-10])), y=valid[,10])
# Fit the classifier on the entire training set
fit.pamr <- pamr.train(pamrTrain)
fit.pamr
# Use cross-validation to select the best regularization parameter
fit.cv.pamr <- pamr.cv(fit.pamr, pamrTrain)
fit.cv.pamr
# Manually select the threshold depending on the plots and on the confusion matrix
pamr.plotcv(fit.cv.pamr)
#Let's compare thresholds=1 and 2 to illustrate the effect of shrinkage
pamr.confusion(fit.cv.pamr, threshold=0.137)
pamr.confusion(fit.cv.pamr, threshold=0.273)
#Get the best threshhold
thresh <- max(fit.cv.pamr$threshold[fit.cv.pamr$error==min(fit.cv.pamr$error)])
thresh
# Refit the classifier on the full dataset, but using the threshold
fit.pamr <- pamr.train(pamrTrain, threshold=0.1367487)
mydata <- list(x=x,y=y)
mytrain <-   pamr.train(mydata)
pamr.plotcen(mytrain, mydata, threshold=2)
mydata <- list(x=x,y=y)
mytrain <-pamr.train(mydata)
pamr.plotcen(mytrain, mydata, threshold=2)
mydata <- list(x=x,y=x)
mytrain <-pamr.train(mydata)
pamr.plotcen(mytrain, mydata, threshold=2)
mydata <- list(x=x,y=y)
mytrain <-pamr.train(mydata)
pamr.plotcen(mytrain, mydata, threshold=2)
set.seed(120)
mydata <- list(x=x,y=y)
mytrain <-   pamr.train(mydata)
pamr.plotcvprob(mytrain,mydata, threshold=0.1367487)
set.seed(120)
mydata <- list(x=x,y=y)
mytrain <- pamr.train(mydata)
pamr.plotcvprob(pamrTrain , mydata, threshold=0.1367487)
set.seed(120)
mydata <- list(x=x,y=y)
mytrain <- pamr.train(mydata)
pamr.plotcvprob(pamrTrain$x, mydata, threshold=0.1367487)
set.seed(120)
mydata <- list(x=x,y=y)
mytrain <- pamr.train(mydata)
pamr.plotcvprob(mytrain,mydata, threshold=0.1367487)
unlink('D:/Dropbox/CS6140/hw3/1_cache', recursive = TRUE)
par("mar")
par(mar=c(1,1,1,1))
par("mar")
graphics.off()
par(mfrow=c(4,2))
par(mar = rep(2, 4))
par(mfrow=c(2,2))
par(mfrow=c(1,1))
knitr::opts_chunk$set(echo = TRUE)
library(pamr)
# Reformat the dataset for parm
pamrTrain <- list(x=t(as.matrix(train[,-10])), y=train[,10])
pamrValid <- list(x=t(as.matrix(valid[,-10])), y=valid[,10])
# Fit the classifier on the entire training set
fit.pamr <- pamr.train(pamrTrain)
fit.pamr
# Use cross-validation to select the best regularization parameter
fit.cv.pamr <- pamr.cv(fit.pamr, pamrTrain)
fit.cv.pamr
# Manually select the threshold depending on the plots and on the confusion matrix
par(mar = rep(2, 4))
pamr.plotcv(fit.cv.pamr)
setwd('D:/Dropbox/CS5700/Projects/Project_3')
data <- read.table('data.txt', header=TRUE, row.names=1, sep='\t')
head(data)
x = data$NewReno
data <- read.table('data.txt', header=TRUE, row.names=1, sep='\t')
head(data)
x = data$Tahoe
y = data$Reno
sd(x)
sd(y)
x = data$NewReno
y = data$Vegas
sd(x)
sd(y)
